/*@push@*/ declare /*@pull@*/ declare
/*@NonDeterm@*/ declare /*@Determ@*/ declare
/*@IntType@*/ declare /*@LongType@*/ declare
/*@NonPersist@*/ declare /*@Persist@*/ declare
/*@Atomic@*/ declare /*@CudaAtomic@*/ declare /*@RaceBug@*/ declare
/*@Thread@*/ declare /*@Warp@*/ declare /*@Block@*/ declare

/*@push@*/ /*@pull@*/ suppress
/*@Thread@*/ /*@Warp@*/ suppress /*@Block@*/ suppress

/*@Atomic@*/ typedef int flag_t; /*@CudaAtomic@*/ typedef cuda::atomic<int> flag_t; /*@RaceBug@*/ typedef int flag_t;
/*@IntType@*/ typedef int data_type; /*@LongType@*/ typedef unsigned long long data_type;

static const int ThreadsPerBlock = 512;
//BlankLine

#include "indigo_mis_edge_cuda.h"
//BlankLine

/*@+NonDeterm@*/ 
static __global__ void init(const ECLgraph g, const int* const sp, data_type* const priority, flag_t* const status, flag_t* const lost, int* const wl1, int* const wlsize) 
/*@-NonDeterm@*/ 
/*@+Determ@*/ 
static __global__ void init(const ECLgraph g, const int* const sp, data_type* const priority, flag_t* const status, flag_t* const status_n, flag_t* const lost, int* const wl1, int* const wlsize) 
/*@-Determ@*/ 
{
  // initialize arrays
  const int v = threadIdx.x + blockIdx.x * ThreadsPerBlock;
  if (v < g.nodes)
  {
    /*@IntType@*/ priority[v] = hash(v + 712313887); /*@LongType@*/ priority[v] = ((unsigned long long)hash(v + 712313887)) | ((unsigned long long)hash(v + 683067839) << (sizeof (unsigned int) * 8));
    status[v] = undecided;
    /*@NonDeterm@*/ /*@Determ@*/ status_n[v] = undecided;
    lost[v] = 0;
  }
  
  if (v < g.edges)
  {
    // initialize worklist
    if (sp[v] < g.nlist[v]) {
      wl1[atomicAdd(wlsize, 1)] = v;
    }
  }
}
//BlankLine

/*@+NonDeterm@*/ 
static __global__ void mis(const ECLgraph g, const int* const sp, const data_type* const priority, flag_t* const status, flag_t* const lost, const int* const wl1, const int wl1size) 
/*@-NonDeterm@*/ 
/*@+Determ@*/ 
static __global__ void mis(const ECLgraph g, const int* const sp, const data_type* const priority, flag_t* const status, flag_t* const status_n, flag_t* const lost, const int* const wl1, const int wl1size)
/*@-Determ@*/
{
  // go over all edges in wl1
  /*@+NonPersist@*/
  int w = threadIdx.x + blockIdx.x * ThreadsPerBlock;
  if (w < wl1size) {
  /*@-NonPersist@*/
  
  /*@+Persist@*/
  int tid = threadIdx.x + blockIdx.x * ThreadsPerBlock;
  for (int w = tid; w < wl1size; w += gridDim.x * ThreadsPerBlock) {
  /*@-Persist@*/

    //BlankLine
    int e = wl1[w];
    const int src = sp[e];
    const int dst = g.nlist[e];
    /*@Atomic@*/ const int srcStatus = atomicRead(&status[src]); /*@CudaAtomic@*/ const int srcStatus = status[src].load(); /*@RaceBug@*/ const int srcStatus = status[src];
    /*@Atomic@*/ const int dstStatus = atomicRead(&status[dst]); /*@CudaAtomic@*/ const int dstStatus = status[dst].load(); /*@RaceBug@*/ const int dstStatus = status[dst];
    //BlankLine
    
    // if one is included, exclude the other
    if (srcStatus == included) {
      /*@+NonDeterm@*/
      /*@Atomic@*/ atomicWrite(&status[dst], excluded); /*@CudaAtomic@*/ status[dst].store(excluded); /*@RaceBug@*/ status[dst] = excluded; /*@RaceBug@*/ status[dst] = excluded;
      /*@-NonDeterm@*/
      /*@+Determ@*/
      /*@Atomic@*/ atomicWrite(&status_n[dst], excluded); /*@CudaAtomic@*/ status_n[dst].store(excluded); /*@RaceBug@*/ status_n[dst] = excluded; /*@RaceBug@*/ suppress
      /*@-Determ@*/
    }
    else if (dstStatus == included) {
      /*@+NonDeterm@*/
      /*@Atomic@*/ atomicWrite(&status[src], excluded); /*@CudaAtomic@*/ status[src].store(excluded); /*@RaceBug@*/ status[src] = excluded;
      /*@-NonDeterm@*/
      /*@+Determ@*/
      /*@Atomic@*/ atomicWrite(&status_n[src], excluded); /*@CudaAtomic@*/ status_n[src].store(excluded); /*@RaceBug@*/ suppress
      /*@-Determ@*/
    } else if (srcStatus == undecided && dstStatus == undecided) { 
    // if both undecided -> mark lower as lost
      if (priority[src] < priority[dst]) {
        /*@Atomic@*/ atomicWrite(&lost[src], 1); /*@CudaAtomic@*/ lost[src].store(1); /*@RaceBug@*/ lost[src] = 1;
      } else {
        /*@Atomic@*/ atomicWrite(&lost[dst], 1); /*@CudaAtomic@*/ lost[dst].store(1); /*@RaceBug@*/ lost[dst] = 1;
      }
    }
  }
}
//BlankLine

/*@+NonDeterm@*/ 
static __global__ void mis_vertex_pass(const ECLgraph g, const int* const sp, data_type* const priority, flag_t* const status, flag_t* const lost, const int* const wl1, const int wl1size, int* const wl2, int* const wl2size, const int iter, int* const time)
/*@-NonDeterm@*/ 
/*@+Determ@*/ 
static __global__ void mis_vertex_pass(const ECLgraph g, const int* const sp, data_type* const priority, flag_t* const status, flag_t* const status_n, flag_t* const lost, const int* const wl1, const int wl1size, int* const wl2, int* const wl2size, const int iter, int* const time)
/*@-Determ@*/
{
  // go over all edges in wl1 and check if lost
  /*@+NonPersist@*/
  int w = threadIdx.x + blockIdx.x * ThreadsPerBlock;
  if (w < wl1size) {
  /*@-NonPersist@*/

  /*@+Persist@*/
  int tid = threadIdx.x + blockIdx.x * ThreadsPerBlock;
  for (int w = tid; w < wl1size; w += gridDim.x * ThreadsPerBlock) {
  /*@-Persist@*/
  
    //BlankLine
    const int e = wl1[w];
    const int src = sp[e];
    const int dst = g.nlist[e];
    /*@Atomic@*/ const int srcStatus = atomicRead(&status[src]); /*@CudaAtomic@*/ const int srcStatus = status[src].load(); /*@RaceBug@*/ const int srcStatus = status[src];
    /*@Atomic@*/ const int dstStatus = atomicRead(&status[dst]); /*@CudaAtomic@*/ const int dstStatus = status[dst].load();
    //BlankLine
    
    // if src won
    if (lost[src] == 0) {
      if (srcStatus == undecided) {
      // and is undecided -> include
        /*@+NonDeterm@*/
        /*@Atomic@*/ atomicWrite(&status[src], included); /*@CudaAtomic@*/ status[src].store(included);
        /*@-NonDeterm@*/
        /*@+Determ@*/
        /*@Atomic@*/ atomicWrite(&status_n[src], included); /*@CudaAtomic@*/ status_n[src].store(included);
        /*@-Determ@*/
      }
    }
    // if dst won
    if (lost[dst] == 0) {
      if (dstStatus == undecided) {
      // and is undecided -> include
        /*@+NonDeterm@*/
        /*@Atomic@*/ atomicWrite(&status[dst], included); /*@CudaAtomic@*/ status[dst].store(included);
        /*@-NonDeterm@*/
        /*@+Determ@*/
        /*@Atomic@*/ atomicWrite(&status_n[dst], included); /*@CudaAtomic@*/ status_n[dst].store(included);
        /*@-Determ@*/
      }
    }
    // if either is still undecided, keep it in WL
    if (srcStatus == undecided || dstStatus == undecided) {
      if (atomicMax(&time[e], iter) < iter) {
        wl2[atomicAdd(wl2size, 1)] = e;
      }
    }
  }
}
//BlankLine

static __global__ void mis_last_pass(flag_t* const status, const int size)
{
  /*@+NonPersist@*/
  int w = threadIdx.x + blockIdx.x * ThreadsPerBlock;
  if (w < size) {
  /*@-NonPersist@*/

  /*@+Persist@*/
  int tid = threadIdx.x + blockIdx.x * ThreadsPerBlock;
  for (int w = tid; w < size; w += gridDim.x * ThreadsPerBlock) {
  /*@-Persist@*/
  
    if (status[w] == undecided)
    {
      status[w] = included;
    }
  }
}
//BlankLine

static double GPUmis_edge(const ECLgraph g, const int* const sp, data_type* const priority, int* const status)
{
  data_type* d_priority;
  if (cudaSuccess != cudaMalloc((void **)&d_priority, g.nodes * sizeof(data_type))) fprintf(stderr, "ERROR: could not allocate d_priority\n");
  flag_t* d_status;
  if (cudaSuccess != cudaMalloc((void **)&d_status, g.nodes * sizeof(flag_t))) fprintf(stderr, "ERROR: could not allocate d_status\n");
  flag_t* d_lost;
  if (cudaSuccess != cudaMalloc((void **)&d_lost, g.nodes * sizeof(flag_t))) fprintf(stderr, "ERROR: could not allocate d_lost\n");
  /*@+Determ@*/
  flag_t* d_status_new;
  if (cudaSuccess != cudaMalloc((void **)&d_status_new, g.nodes * sizeof(flag_t))) fprintf(stderr, "ERROR: could not allocate d_status_new\n");
  /*@-Determ@*/
  //BlankLine

  int* d_wl1;
  if (cudaSuccess != cudaMalloc((void **)&d_wl1, MAX(g.edges, g.nodes) * sizeof(int))) fprintf(stderr, "ERROR: could not allocate d_wl1\n");
  int* d_wl1size;
  if (cudaSuccess != cudaMalloc((void **)&d_wl1size, sizeof(int))) fprintf(stderr, "ERROR: could not allocate d_wl1size\n");

  int* d_wl2;
  if (cudaSuccess != cudaMalloc((void **)&d_wl2, MAX(g.edges, g.nodes) * sizeof(int))) fprintf(stderr, "ERROR: could not allocate d_wl2\n");
  int* d_wl2size;
  if (cudaSuccess != cudaMalloc((void **)&d_wl2size, sizeof(int))) fprintf(stderr, "ERROR: could not allocate d_wl2size\n");

  int* d_time;
  if (cudaSuccess != cudaMalloc((void **)&d_time, sizeof(int) * g.edges)) {fprintf(stderr, "ERROR: could not allocate memory\n"); exit(-1);}
  cudaMemset(d_time, 0, sizeof(int) * g.edges);

  int wlsize;

  /*@+Persist@*/
  const int ThreadsBound = GPUinfo(0, false);
  const int blocks = ThreadsBound / ThreadsPerBlock;
  /*@-Persist@*/
  
  cudaMemset(d_wl1size, 0, sizeof(int));
  
  //BlankLine
  /*@NonDeterm@*/ init<<<(g.edges + ThreadsPerBlock - 1) / ThreadsPerBlock, ThreadsPerBlock>>>(g, sp, d_priority, d_status, d_lost, d_wl1, d_wl1size); /*@Determ@*/ init<<<(g.edges + ThreadsPerBlock - 1) / ThreadsPerBlock, ThreadsPerBlock>>>(g, sp, d_priority, d_status, d_status_new, d_lost, d_wl1, d_wl1size);
  //BlankLine
  if (cudaSuccess != cudaMemcpy(&wlsize, d_wl1size, sizeof(int), cudaMemcpyDeviceToHost)) fprintf(stderr, "ERROR: copying of wlsize from device d_wl1size failed\n");

  //BlankLine
  struct timeval beg, end;
  gettimeofday(&beg, NULL);
  //BlankLine
  
  int iter = 0;
  do {
    iter++;
    cudaMemset(d_wl2size, 0, sizeof(int));
    /*@NonPersist@*/ const int blocks = (wlsize + ThreadsPerBlock - 1) / ThreadsPerBlock; /*@Persist@*/

    //BlankLine
    // edge pass
    /*@+NonDeterm@*/
    mis<<<blocks, ThreadsPerBlock>>>(g, sp, d_priority, d_status, d_lost, d_wl1, wlsize); 
    /*@-NonDeterm@*/
    /*@+Determ@*/
    mis<<<blocks, ThreadsPerBlock>>>(g, sp, d_priority, d_status, d_status_new, d_lost, d_wl1, wlsize);
    /*@-Determ@*/
    //BlankLine
    
    /*@NonDeterm@*/ /*@Determ@*/ if (cudaSuccess != cudaMemcpy(d_status, d_status_new, g.nodes * sizeof(flag_t), cudaMemcpyDeviceToDevice)) fprintf(stderr, "ERROR: copying of d_status_new to d_status on device failed\n");
    
    // vertex pass
    /*@+NonDeterm@*/
    mis_vertex_pass<<<blocks, ThreadsPerBlock>>>(g, sp, d_priority, d_status, d_lost, d_wl1, wlsize, d_wl2, d_wl2size, iter, d_time); 
    /*@-NonDeterm@*/
    /*@+Determ@*/
    mis_vertex_pass<<<blocks, ThreadsPerBlock>>>(g, sp, d_priority, d_status, d_status_new, d_lost, d_wl1, wlsize, d_wl2, d_wl2size, iter, d_time);
    /*@-Determ@*/
    //BlankLine
    
    if (cudaSuccess != cudaMemcpy(&wlsize, d_wl2size, sizeof(int), cudaMemcpyDeviceToHost)) { fprintf(stderr, "ERROR: copying of wlsize from device failed\n"); break; }
    cudaMemset(d_lost, 0, g.nodes * sizeof(flag_t));
    SWAP(d_wl1, d_wl2);
    SWAP(d_wl1size, d_wl2size);
    /*@NonDeterm@*/ /*@Determ@*/ if (cudaSuccess != cudaMemcpy(d_status, d_status_new, g.nodes * sizeof(flag_t), cudaMemcpyDeviceToDevice)) fprintf(stderr, "ERROR: copying of d_status_new to d_status on device failed\n");
  } while (wlsize > 0);

  //BlankLine
  /*@+NonPersist@*/
  const int blocks = (g.nodes + ThreadsPerBlock - 1) / ThreadsPerBlock;
  /*@-NonPersist@*/
  // include all remaining nodes that have no edges
  mis_last_pass<<<blocks, ThreadsPerBlock>>>(d_status, g.nodes); 

  //BlankLine
  cudaDeviceSynchronize();
  gettimeofday(&end, NULL);
  const double runtime = end.tv_sec - beg.tv_sec + (end.tv_usec - beg.tv_usec) / 1000000.0;
  //BlankLine
  
  CheckCuda();
  if (cudaSuccess != cudaMemcpy(status, d_status, g.nodes * sizeof(flag_t), cudaMemcpyDeviceToHost)) fprintf(stderr, "ERROR: copying of status from device failed\n"); 
  //BlankLine

  // determine and print set size
  int cnt = 0;
  for (int v = 0; v < g.nodes; v++) {
    if (status[v] == included) cnt++;
  }
  printf("iterations: %d,  elements in set: %d (%.1f%%)\n", iter, cnt, 100.0 * cnt / g.nodes);
  //BlankLine

  /*@NonDeterm@*/ /*@Determ@*/ cudaFree(d_status_new);
  cudaFree(d_status);
  cudaFree(d_priority);
  cudaFree(d_lost);
  cudaFree(d_wl1);
  cudaFree(d_wl1size);
  cudaFree(d_wl2);
  cudaFree(d_wl2size);
  return runtime;
}
