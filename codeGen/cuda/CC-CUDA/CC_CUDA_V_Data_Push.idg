/*@NonDeterm@*/ declare /*@Determ@*/ declare
/*@IntType@*/ declare /*@LongType@*/ declare
/*@ReadWrite@*/ declare /*@ReadModifyWrite@*/ declare

/*@NonPersist@*/ declare /*@Persist@*/ declare
/*@Atomic@*/ declare /*@CudaAtomic@*/ #include <cuda/atomic> /*@RaceBug@*/ declare
/*@Thread@*/ declare /*@Warp@*/ declare /*@Block@*/ declare
/*@NonDup@*/ declare /*@Dup@*/ declare

/*@NoNbrBoundsBug@*/ declare /*@NbrBoundsBug@*/ declare
/*@NoExcessThreadsBug@*/ declare /*@ExcessThreadsBug@*/ declare /*@NoBoundsBug@*/ declare /*@BoundsBug@*/ declare

/*@+Persist@*/
/*@NoExcessThreadsBug@*/ suppress /*@ExcessThreadsBug@*/ suppress /*@NoBoundsBug@*/ /*@BoundsBug@*/ 
/*@-Persist@*/

/*@+ReadWrite@*/
/*@NonDup@*/ /*@Dup@*/ suppress
/*@-ReadWrite@*/

/*@+ReadWrite@*/
/*@NonDeterm@*/ /*@Determ@*/ suppress
/*@-ReadWrite@*/

/*@+ReadModifyWrite@*/
/*@NoLivelockBug@*/ /*@LivelockBug@*/ suppress
/*@-ReadModifyWrite@*/

/*@+NonDeterm@*/ /*@+ReadWrite@*/
/*@NonDup@*/ /*@Dup@*/ suppress
/*@-NonDeterm@*/ /*@-ReadWrite@*/

/*@Atomic@*/ typedef int flag_t; /*@CudaAtomic@*/ typedef cuda::atomic<int> flag_t; /*@RaceBug@*/ typedef int flag_t;

/*@+IntType@*/
/*@Atomic@*/ typedef int data_type; /*@CudaAtomic@*/ typedef cuda::atomic<int> data_type; /*@RaceBug@*/ typedef int data_type;
typedef int basic_t;
/*@-IntType@*/

/*@+LongType@*/
/*@Atomic@*/ typedef unsigned long long data_type; /*@CudaAtomic@*/ typedef cuda::atomic<unsigned long long> data_type; /*@RaceBug@*/ typedef unsigned long long data_type;
typedef unsigned long long basic_t;
/*@-LongType@*/


static const int ThreadsPerBlock = 512;
/*@Thread@*/ /*@Warp@*/ static const int WarpSize = 32; /*@Block@*/
//BlankLine

#include "indigo_cc_vertex_cuda.h"
//BlankLine

/*@NonDeterm@*/ static __global__ void init(data_type* const label, const int size, const ECLgraph g, int* const wl1, int* const wlsize) /*@Determ@*/ static __global__ void init(data_type* const label, data_type* const label_n, const int size, const ECLgraph g, int* const wl1, int* const wlsize)
{
  // initialize label array
  const int v = threadIdx.x + blockIdx.x * ThreadsPerBlock;
  if (v < size) {
    /*@+Determ@*/
    /*@Atomic@*/ label_n[v] = v; /*@CudaAtomic@*/ label_n[v].store(v); /*@RaceBug@*/ label_n[v] = v;
    /*@-Determ@*/
    /*@Atomic@*/ label[v] = v; /*@CudaAtomic@*/ label[v].store(v); /*@RaceBug@*/ label[v] = v;
    wl1[v] = v;
  }
  // initialize worklist
  if (v == 0) {
    // wl1[0] = 0;
    *wlsize = size;
  }
}
//BlankLine

/*@+NonDup@*/
/*@NonDeterm@*/ static __global__ void cc_vertex_data(const ECLgraph g, data_type* const label, const int* const wl1, const int wl1size, int* const wl2, int* const wl2size, const int iter, int* const time) /*@Determ@*/ static __global__ void cc_vertex_data(const ECLgraph g, data_type* const label, data_type* const label_n, const int* const wl1, const int wl1size, int* const wl2, int* const wl2size, const int iter, int* const time)
/*@-NonDup@*/
/*@+Dup@*/
/*@NonDeterm@*/ static __global__ void cc_vertex_data(const ECLgraph g, data_type* const label, const int* const wl1, const int wl1size, int* const wl2, int* const wl2size) /*@Determ@*/ static __global__ void cc_vertex_data(const ECLgraph g, data_type* const label, data_type* const label_n, const int* const wl1, const int wl1size, int* const wl2, int* const wl2size)
/*@-Dup@*/
{
  /*@NoFieldBug@*/ int N = wl1size; /*@FieldBug@*/ int N = g.nodes;
  /*@+NonPersist@*/
  /*@Thread@*/ int idx = threadIdx.x + blockIdx.x * ThreadsPerBlock; /*@Warp@*/ int idx = (threadIdx.x + blockIdx.x * ThreadsPerBlock) / WarpSize; /*@Block@*/ int idx = blockIdx.x;
  /*@NoExcessThreadsBug@*/ if (idx < N) { /*@ExcessThreadsBug@*/ { /*@NoBoundsBug@*/ suppress /*@BoundsBug@*/ suppress
  /*@-NonPersist@*/

  /*@+Persist@*/
  /*@Thread@*/ int tid = threadIdx.x + blockIdx.x * ThreadsPerBlock; /*@Warp@*/ int tid = (threadIdx.x + blockIdx.x * ThreadsPerBlock) / WarpSize; /*@Block@*/ int tid = blockIdx.x;
  /*@-Persist@*/

  /*@+Persist@*/ /*@+NoBoundsBug@*/ 
  /*@Thread@*/ for (int idx = tid; idx < N; idx += gridDim.x * ThreadsPerBlock) { /*@Warp@*/ for (int idx = tid; idx < N; idx += gridDim.x * (ThreadsPerBlock / WarpSize)) { /*@Block@*/ for (int idx = tid; idx < N; idx += gridDim.x) {
  /*@-Persist@*/ /*@-NoBoundsBug@*/

  /*@+Persist@*/ /*@+BoundsBug@*/ 
  /*@Thread@*/ for (int idx = tid; idx <= N; idx += gridDim.x * ThreadsPerBlock) { /*@Warp@*/ for (int idx = tid; idx <= N; idx += gridDim.x * (ThreadsPerBlock / WarpSize)) { /*@Block@*/ for (int idx = tid; idx <= N; idx += gridDim.x) {
  /*@-Persist@*/ /*@-BoundsBug@*/ 

    const int src = wl1[idx];
    /*@+NonDeterm@*/
    /*@Atomic@*/ const data_type new_label = atomicRead(&label[src]); /*@CudaAtomic@*/ const data_type new_label = label[src].load(); /*@RaceBug@*/ const data_type new_label = label[src];
    /*@-NonDeterm@*/
    /*@+Determ@*/
    /*@Atomic@*/ const data_type new_label = label[src]; /*@CudaAtomic@*/ const data_type new_label = label[src].load(); /*@RaceBug@*/ const data_type new_label = label[src];
    /*@-Determ@*/

    const int beg = g.nindex[src];
    const int end = g.nindex[src + 1];
    //BlankLine

    /*@+Determ@*/
    /*@Thread@*/ /*@Warp@*/ const int lane = threadIdx.x % WarpSize; /*@Block@*/
    /*@-Determ@*/

    /*@+ReadWrite@*/ /*@+NonDeterm@*/
    /*@Thread@*/ /*@Warp@*/ const int warp = threadIdx.x / WarpSize; /*@Block@*/
    /*@Thread@*/ /*@Warp@*/ const int lane = threadIdx.x % WarpSize; /*@Block@*/
    /*@Thread@*/ bool updated = false; /*@Warp@*/ __shared__ bool updated[ThreadsPerBlock / WarpSize]; /*@Block@*/ __shared__ bool updated;
    /*@Thread@*/ /*@Warp@*/ if (lane == 0) updated[warp] = false; /*@Block@*/ if (threadIdx .x == 0) updated = false;
    /*@Thread@*/ /*@Warp@*/ __syncwarp(); /*@Block@*/ __syncthreads();
    /*@-ReadWrite@*/ /*@-NonDeterm@*/

    /*@+NoNbrBoundsBug@*/
    /*@Thread@*/ for (int i = beg; i < end; i++) { /*@Warp@*/ for (int i = beg + threadIdx.x % WarpSize; i < end; i += WarpSize) { /*@Block@*/ for (int i = beg + threadIdx.x; i < end; i += ThreadsPerBlock) {
    /*@-NoNbrBoundsBug@*/
    /*@+NbrBoundsBug@*/
    /*@Thread@*/ for (int i = beg; i <= end; i++) { /*@Warp@*/ for (int i = beg + threadIdx.x % WarpSize; i <= end; i += WarpSize) { /*@Block@*/ for (int i = beg + threadIdx.x; i <= end; i += ThreadsPerBlock) {
    /*@-NbrBoundsBug@*/
      const int dst = g.nlist[i];
      //BlankLine

      /*@+NonDeterm@*/ /*@+ReadWrite@*/
      /*@Atomic@*/ const data_type d = atomicRead(&label[dst]); /*@CudaAtomic@*/ const data_type d = label[dst].load(); /*@RaceBug@*/ const data_type d = label[dst];
      /*@NoLivelockBug@*/ if (d > new_label) { /*@LivelockBug@*/ if (d >= new_label) {
      /*@Atomic@*/ atomicWrite(&label[dst], new_label); /*@CudaAtomic@*/ label[dst].store(new_label); /*@RaceBug@*/ label[dst] = new_label;
      /*@-NonDeterm@*/ /*@-ReadWrite@*/

      /*@+NonDeterm@*/ /*@+ReadModifyWrite@*/
      /*@Atomic@*/ if (atomicMin(&label[dst], new_label) > new_label) { /*@CudaAtomic@*/ if (label[dst].fetch_min(new_label) > new_label) { /*@RaceBug@*/ suppress
      /*@-NonDeterm@*/ /*@-ReadModifyWrite@*/

      /*@+Determ@*/ /*@+ReadModifyWrite@*/
      /*@Atomic@*/ if (atomicMin(&label_n[dst], new_label) > new_label) { /*@CudaAtomic@*/ if (label_n[dst].fetch_min(new_label) > new_label) { /*@RaceBug@*/ suppress
      /*@-Determ@*/ /*@-ReadModifyWrite@*/

        /*@+NonDup@*/
        if (atomicMax(&time[dst], iter) != iter) {
          wl2[atomicAdd(wl2size, 1)] = dst;
        }
        /*@-NonDup@*/
        /*@+Dup@*/
        wl2[atomicAdd(wl2size, 1)] = dst;
        /*@-Dup@*/
        
        /*@+NonDeterm@*/ /*@+ReadWrite@*/
        /*@Thread@*/ updated = true; /*@Warp@*/ updated[warp] = true; /*@Block@*/ updated = true;
        /*@-NonDeterm@*/ /*@-ReadWrite@*/
      }
    }
    /*@Thread@*/ /*@Warp@*/ __syncwarp(); /*@Block@*/ __syncthreads();

    /*@+NonDeterm@*/ /*@+ReadWrite@*/ /*@+NonDup@*/
    /*@Thread@*/ /*@Warp@*/ if (lane == 0) { /*@Block@*/ if (threadIdx.x == 0) {
      /*@Thread@*/ if (updated) { /*@Warp@*/ if (updated[warp]) { /*@Block@*/ if (updated) {
        if (atomicMax(&time[src], iter) < iter) {
          wl2[atomicAdd(wl2size, 1)] = src;
        }
      /*@Thread@*/ /*@Warp@*/ } /*@Block@*/ }
    }
    /*@-NonDeterm@*/ /*@-ReadWrite@*/ /*@-NonDup@*/

    /*@+Determ@*/
    /*@Thread@*/ /*@Warp@*/ if (lane == 0) { /*@Block@*/ if (threadIdx.x == 0) {
    /*@Atomic@*/ atomicMin(&label_n[src], new_label); /*@CudaAtomic@*/ label_n[src].fetch_min(new_label); /*@RaceBug@*/ suppress
    /*@Thread@*/ /*@Warp@*/ } /*@Block@*/ }
    /*@-Determ@*/

    /*@+Persist@*/
    /*@Thread@*/ /*@Warp@*/ __syncwarp(); /*@Block@*/ __syncthreads();
    /*@-Persist@*/
  }
}

static double GPUcc_vertex(const ECLgraph g, basic_t* const label)
{
  data_type* d_label;
  if (cudaSuccess != cudaMalloc((void **)&d_label, g.nodes * sizeof(data_type))) fprintf(stderr, "ERROR: could not allocate d_label\n");
  /*@+Determ@*/
  data_type* d_label_new;
  if (cudaSuccess != cudaMalloc((void **)&d_label_new, g.nodes * sizeof(data_type))) fprintf(stderr, "ERROR: could not allocate d_label_new\n");
  /*@-Determ@*/

  int* d_wl1;
  if (cudaSuccess != cudaMalloc((void **)&d_wl1, MAX(g.edges, g.nodes) * sizeof(int))) fprintf(stderr, "ERROR: could not allocate d_wl1\n");
  int* d_wl1size;
  if (cudaSuccess != cudaMalloc((void **)&d_wl1size, sizeof(int))) fprintf(stderr, "ERROR: could not allocate d_wl1size\n");

  int* d_wl2;
  if (cudaSuccess != cudaMalloc((void **)&d_wl2, MAX(g.edges, g.nodes) * sizeof(int))) fprintf(stderr, "ERROR: could not allocate d_wl2\n");
  int* d_wl2size;
  if (cudaSuccess != cudaMalloc((void **)&d_wl2size, sizeof(int))) fprintf(stderr, "ERROR: could not allocate d_wl2size\n");

  /*@+NonDup@*/
  int* d_time;
  if (cudaSuccess != cudaMalloc((void **)&d_time, sizeof(int) * g.nodes)) {fprintf(stderr, "ERROR: could not allocate memory\n"); exit(-1);}
  cudaMemset(d_time, 0, sizeof(int) * g.nodes);
  /*@-NonDup@*/

  int wlsize;

  /*@+Persist@*/
  const int ThreadsBound = GPUinfo(0);
  const int blocks = ThreadsBound / ThreadsPerBlock;
  /*@-Persist@*/

  //BlankLine
  /*@NonDeterm@*/ init<<<(g.nodes + ThreadsPerBlock - 1) / ThreadsPerBlock, ThreadsPerBlock>>>(d_label, g.nodes, g, d_wl1, d_wl2size); /*@Determ@*/ init<<<(g.nodes + ThreadsPerBlock - 1) / ThreadsPerBlock, ThreadsPerBlock>>>(d_label, d_label_new, g.nodes, g, d_wl1, d_wl2size);
  //BlankLine
  if (cudaSuccess != cudaMemcpy(&wlsize, d_wl2size, sizeof(int), cudaMemcpyDeviceToHost)) fprintf(stderr, "ERROR: copying of wlsize from device failed\n");
  if (cudaSuccess != cudaMemcpy(d_wl1size, &wlsize, sizeof(int), cudaMemcpyHostToDevice)) fprintf(stderr, "ERROR: copying of wl1size to device failed\n");
  // iterate until no more changes
  int iter = 0;
  //BlankLine

  if (wlsize == 0) {fprintf(stderr, "Warning: invalid input\n"); exit(-1);}
  timeval start, end;
  gettimeofday(&start, NULL);
  //BlankLine
  do {
    iter++;
    cudaMemset(d_wl2size, 0, sizeof(int));
    /*@+NonPersist@*/
    /*@Thread@*/ const int blocks = (wlsize + ThreadsPerBlock - 1) / ThreadsPerBlock; /*@Warp@*/ const int blocks = ((long)wlsize * WarpSize + ThreadsPerBlock - 1) / ThreadsPerBlock; /*@Block@*/ const int blocks = wlsize;
    /*@-NonPersist@*/

    //BlankLine
    /*@+NonDup@*/
    /*@NonDeterm@*/ cc_vertex_data<<<blocks, ThreadsPerBlock>>>(g, d_label, d_wl1, wlsize, d_wl2, d_wl2size, iter, d_time); /*@Determ@*/ cc_vertex_data<<<blocks, ThreadsPerBlock>>>(g, d_label, d_label_new, d_wl1, wlsize, d_wl2, d_wl2size, iter, d_time);
    /*@-NonDup@*/
    /*@+Dup@*/
    /*@NonDeterm@*/ cc_vertex_data<<<blocks, ThreadsPerBlock>>>(g, d_label, d_wl1, wlsize, d_wl2, d_wl2size); /*@Determ@*/ cc_vertex_data<<<blocks, ThreadsPerBlock>>>(g, d_label, d_label_new, d_wl1, wlsize, d_wl2, d_wl2size);
    /*@-Dup@*/
    //BlankLine
    if (cudaSuccess != cudaMemcpy(&wlsize, d_wl2size, sizeof(int), cudaMemcpyDeviceToHost)) fprintf(stderr, "ERROR: copying of wlsize from device failed\n");
    SWAP(d_wl1, d_wl2);
    SWAP(d_wl1size, d_wl2size);
    /*@NonDeterm@*/ /*@Determ@*/ SWAP(d_label, d_label_new);
  } while (wlsize > 0);
  //BlankLine

  cudaDeviceSynchronize();
  gettimeofday(&end, NULL);
  //BlankLine

  double runtime = end.tv_sec + end.tv_usec / 1000000.0 - start.tv_sec - start.tv_usec / 1000000.0;
  CheckCuda();
  printf("iterations: %d\n", iter);
  //BlankLine

  /*@NonDeterm@*/ if (cudaSuccess != cudaMemcpy(label, d_label, g.nodes * sizeof(data_type), cudaMemcpyDeviceToHost)) fprintf(stderr, "ERROR: copying of label from device failed\n"); /*@Determ@*/ if (cudaSuccess != cudaMemcpy(label, d_label_new, g.nodes * sizeof(data_type), cudaMemcpyDeviceToHost)) fprintf(stderr, "ERROR: copying of label from device failed\n");

  //BlankLine
  cudaFree(d_label);
  cudaFree(d_wl1);
  cudaFree(d_wl1size);
  cudaFree(d_wl2);
  cudaFree(d_wl2size);
  /*@NonDup@*/ cudaFree(d_time); /*@Dup@*/
  return runtime;
}
